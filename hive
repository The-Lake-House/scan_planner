#!/usr/bin/env python

import argparse
import sys

import pymetastore.metastore

import utils

parser = argparse.ArgumentParser()
parser.add_argument('database_name')
parser.add_argument('table_name')
parser.add_argument('--hms-host', default='localhost')
parser.add_argument('--hms-port', default=9083)
args = parser.parse_args()

with pymetastore.metastore.HMS.create(host=args.hms_host, port=args.hms_port) as hms:
    try:
        table = hms.get_table(
            database_name=args.database_name,
            table_name=args.table_name,
        )
    except pymetastore.hive_metastore.ttypes.NoSuchObjectException:
        print(f'Table {args.table_name} does not exist', file=sys.stderr)
        sys.exit(1)
    partition_locations = []
    if table.partition_columns:
        partitions = hms.get_partitions(
            database_name=args.database_name,
            table_name=args.table_name
        )
        for partition in partitions:
            partition_locations.append(partition.sd.location)
    else:
        partition_locations.append(table.storage.location)
    data_files = []
    for partition_location in partition_locations:
        s3_bucket, s3_prefix = utils.parse_s3a(partition_location)
        for obj in utils.s3_list_objects(s3_bucket, s3_prefix + '/'):
            if '_SUCCESS' not in obj['Key']:
                data_files.append(obj['Key'])
    for data_file in data_files:
        print(f's3a://{s3_bucket}/{data_file}')
